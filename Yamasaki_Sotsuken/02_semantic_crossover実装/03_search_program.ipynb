{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.node import Node\n",
    "from local.constnode import ConstNode\n",
    "from local.varnode import VarNode\n",
    "from local.funcnode import FuncNode\n",
    "from local.func import *\n",
    "from local.treeoptimizer import TreeOptimizer\n",
    "from local.crossover import *\n",
    "from local.Optimizer import *\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import graphviz\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, losses, metrics, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder():\n",
    "    date = datetime.datetime.today()\n",
    "    folder_path = str(date.year)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "\n",
    "    folder_path += \"/\"+str(date.month) +\"_\"+str(date.day)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "\n",
    "    folder_path += \"/\"+str(date.hour)+\"_\"+str(date.minute)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "        \n",
    "    return folder_path\n",
    "\n",
    "\n",
    "def Tounament_select(score_list, generation, Selection_size):\n",
    "    candidate = random.sample(range(len(score_list)), Selection_size)\n",
    "    candidate_score = [score_list[i] for i in candidate]\n",
    "    index = candidate_score.index(max(candidate_score))\n",
    "    return copy.deepcopy(generation[candidate[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population = 50\n",
    "Max_generation = 500\n",
    "\n",
    "Mutation_rate = 0.2\n",
    "Crossover_rate = 0.8\n",
    "\n",
    "Selection_size = 2\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 10\n",
    "\n",
    "loss_obj = metrics.Mean()\n",
    "accuracy_obj = metrics.SparseCategoricalAccuracy()\n",
    "val_loss_obj = metrics.SparseCategoricalCrossentropy()\n",
    "val_accuracy_obj = metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "generation = []\n",
    "generation += [Momentum(learning_rate=0.01) for _ in range(Population // 2)]\n",
    "generation += [RMSProp() for _ in range(Population // 2)]\n",
    "\n",
    "best_optim = SGD()\n",
    "best_score = 0.0\n",
    "best_score_list = []\n",
    "past_progress = 0\n",
    "folder_path = create_folder()\n",
    "if not os.path.exists(folder_path+\"/best_optim/\"):\n",
    "    os.mkdir(folder_path+\"/best_optim/\")\n",
    "score_progress = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "    x_train, x_test = x_train[..., tf.newaxis] / 255.0, x_test[..., tf.newaxis] / 255.0\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(BATCH_SIZE)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def build_model():\n",
    "    input = layers.Input(shape = (32, 32, 3))\n",
    "    x = layers.Conv2D(32, 3, 2)(input)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(units = 128, activation = \"relu\")(x)\n",
    "    output = layers.Dense(units = 10, activation = \"softmax\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "train_dataset, test_dataset = load_data()\n",
    "\n",
    "model = build_model()\n",
    "model.compile()\n",
    "if not os.path.exists(\"models/\"):\n",
    "    os.mkdir(\"models/\")\n",
    "if not os.path.exists(\"models/model_cifar.keras\"):\n",
    "    model.save_weights(\"models/model_cifar.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_score = 0.6003\n",
    "# folder_path = '2024/1_2/10_4'\n",
    "# read_folder_path = folder_path +f\"/generation{past_progress}\"\n",
    "# pickle_list = glob.glob(read_folder_path +\"/*.pickle\")\n",
    "# generation = []\n",
    "# for path in pickle_list:\n",
    "#     pickle_file = open(path, \"rb\")\n",
    "#     genetic = pickle.load(pickle_file)\n",
    "#     generation.append(genetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:43<00:00, 12.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [09:57<00:00, 11.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [09:54<00:00, 11.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [09:53<00:00, 11.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [09:52<00:00, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:09<00:00, 12.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:33<00:00, 12.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:37<00:00, 12.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:29<00:00, 12.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:28<00:00, 12.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:28<00:00, 12.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:29<00:00, 12.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:33<00:00, 12.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:26<00:00, 12.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:31<00:00, 12.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:30<00:00, 12.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:24<00:00, 12.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:24<00:00, 12.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:24<00:00, 12.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:24<00:00, 12.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:26<00:00, 12.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:24<00:00, 12.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:27<00:00, 12.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:27<00:00, 12.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:28<00:00, 12.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:23<00:00, 12.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:19<00:00, 12.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:22<00:00, 12.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:23<00:00, 12.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:22<00:00, 12.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:26<00:00, 12.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:26<00:00, 12.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:28<00:00, 12.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:31<00:00, 12.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:25<00:00, 12.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:30<00:00, 12.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:35<00:00, 12.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:27<00:00, 12.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:29<00:00, 12.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:26<00:00, 12.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:28<00:00, 12.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:31<00:00, 12.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:30<00:00, 12.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:27<00:00, 12.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [09:07<01:29, 12.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m val_accuracy_obj\u001b[38;5;241m.\u001b[39mreset_state()\n\u001b[0;32m     42\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m train_dataset:\n\u001b[0;32m     44\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m train_step(X, Y)\n\u001b[0;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mmodel_params\u001b[38;5;241m.\u001b[39mappend(copy\u001b[38;5;241m.\u001b[39mdeepcopy(model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "File \u001b[1;32mc:\\Users\\ninomiyalab\\anaconda3\\envs\\tf210_taro_clone2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ninomiyalab\\anaconda3\\envs\\tf210_taro_clone2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ninomiyalab\\anaconda3\\envs\\tf210_taro_clone2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3011\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3010\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3011\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3012\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3013\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3014\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for progress in range(past_progress, Max_generation):\n",
    "    fitness_list = []\n",
    "    save_path = folder_path + f\"/generation{progress}/\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    for index in tqdm(range(len(generation))):\n",
    "\n",
    "        acc_list = []\n",
    "        optimizer = generation[index]\n",
    "        optimizer.model_params = list()\n",
    "        optimizer.grads_params = list()\n",
    "        model.load_weights(\"models/model_cifar.keras\")\n",
    "        penalty = 1e-5 * len(optimizer.make_struct_dict().keys())\n",
    "\n",
    "        @tf.function\n",
    "        def train_step(X, Y):\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred = model(X)\n",
    "                loss = losses.SparseCategoricalCrossentropy()(Y, pred)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            \n",
    "            loss_obj(loss)\n",
    "            accuracy_obj(Y, pred)\n",
    "        \n",
    "            return gradients\n",
    "        \n",
    "        @tf.function\n",
    "        def test_step(X, Y):\n",
    "            pred = model(X)\n",
    "            \n",
    "            val_loss_obj(Y, pred)\n",
    "            val_accuracy_obj(Y, pred)\n",
    "\n",
    "        for i in range(EPOCHS):\n",
    "            \n",
    "            loss_obj.reset_state()\n",
    "            accuracy_obj.reset_state()\n",
    "            val_loss_obj.reset_state()\n",
    "            val_accuracy_obj.reset_state()\n",
    "            gradients = 0\n",
    "            for X, Y in train_dataset:\n",
    "                gradients = train_step(X, Y)\n",
    "            \n",
    "            optimizer.model_params.append(copy.deepcopy(model.trainable_variables))\n",
    "            optimizer.grads_params.append(copy.deepcopy(gradients))\n",
    "            \n",
    "            for X, Y in test_dataset:\n",
    "                test_step(X, Y)\n",
    "        \n",
    "            acc_list.append(val_accuracy_obj.result().numpy())\n",
    "        fitness_list.append(max(acc_list))\n",
    "        # 画像保存に時間がかかったのでコメントアウトしてます\n",
    "        # optimizer.plot_struct(f\"{save_path}/optimizer_{index}_{max(acc_list)}\")\n",
    "        pickle_file = open(f\"{save_path}/optimizer_{index}_{max(acc_list)}.pickle\", mode= \"wb\")\n",
    "        pickle.dump(optimizer, pickle_file)\n",
    "        pickle_file.close()\n",
    "\n",
    "\n",
    "    for index in range(len(fitness_list)):\n",
    "        if fitness_list[index] > best_score:\n",
    "            best_score = fitness_list[index]\n",
    "            best_optim = copy.deepcopy(generation[index])\n",
    "\n",
    "            best_optim.plot_struct(f\"{folder_path}/best_optim/generation_{progress}_{index}_{best_score}\")\n",
    "            pickle_file = open(f\"{folder_path}/best_optim/generation_{progress}_{index}_{best_score}.pickle\", mode= \"wb\")\n",
    "            pickle.dump(best_optim, pickle_file)\n",
    "            pickle_file.close()\n",
    "    \n",
    "    best_score_list.append(best_score)\n",
    "    print(best_score)\n",
    "    json_file = open(f\"{folder_path}/best_optim/score{progress}.json\", \"w\")\n",
    "    json.dump(str(best_score), json_file)\n",
    "    json_file.close()\n",
    "\n",
    "    next_generation = []\n",
    "\n",
    "    # while len(next_generation) < Population:\n",
    "    #     parent1 = Tounament_select(fitness_list, generation, Selection_size)\n",
    "    #     parent2 = Tounament_select(fitness_list, generation, Selection_size)\n",
    "\n",
    "    #     if random.random() < Crossover_rate:\n",
    "    #         parent1, parent2 = semantic_crossover(parent1, parent2, progress, Max_generation)\n",
    "        \n",
    "    #     next_generation.append(parent1)\n",
    "    #     next_generation.append(parent2)\n",
    "    next_generation = copy.deepcopy(generation)\n",
    "    for index, genetic in enumerate(next_generation):\n",
    "        if random.random() < Mutation_rate:\n",
    "            genetic.mutate()\n",
    "\n",
    "    next_generation.append(copy.deepcopy(best_optim))\n",
    "    next_generation.append(Momentum())\n",
    "    next_generation.append(RMSProp())\n",
    "    \n",
    "    generation = next_generation[len(next_generation) - Population:]\n",
    "\n",
    "    # pickleファイルが思ったより容量大きかったので、現世代の評価と進化が終わったら、ひとつ前の世代のpickleファイルを削除\n",
    "    check_path = folder_path + f\"/generation{progress -1}\"\n",
    "    pickle_list = glob.glob(check_path +\"/*.pickle\")\n",
    "    for path in pickle_list:\n",
    "        os.remove(path)\n",
    "\n",
    "    past_progress = progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210_taro_clone2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
