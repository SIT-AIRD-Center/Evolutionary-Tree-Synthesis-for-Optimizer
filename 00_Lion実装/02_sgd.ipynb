{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.node import Node\n",
    "from local.constnode import ConstNode\n",
    "from local.varnode import VarNode\n",
    "from local.funcnode import FuncNode\n",
    "from local.func import *\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import graphviz\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, losses, metrics, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeOptimizer:\n",
    "    # 一つの木には1つの数学演算子とその引数(定数,変数)で構成する\n",
    "    mutate_probability = 0.1\n",
    "    max_depth = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        # 構成する木の本数を決定\n",
    "        self.tree_num = random.randint(1,10)\n",
    "        # 仮枠の木をはやす\n",
    "        self.tree_list = [FuncNode(max_depth=self.max_depth) for i in range(self.tree_num)]\n",
    "        # 引数を決める際に，他の木の出力を用いられるように，set_random_idの時に用いる辞書を作成\n",
    "        self.tree_dict = {i : {\"node_type\" : \"function\"} for i in range(self.tree_num)}\n",
    "\n",
    "        self.set_node_id()\n",
    "        self.set_random_id()\n",
    "        self.set_save_flag()\n",
    "        self.initialize_state()\n",
    "\n",
    "    def build(self, var_list):\n",
    "        for i in range(self.tree_num):\n",
    "            self.tree_list[i].save_flag = True\n",
    "            self.tree_list[i].build(var_list)\n",
    "            self.iteration_slots = list()\n",
    "            for V in var_list:\n",
    "                self.iteration_slots.append( tf.Variable( tf.zeros(V.shape) ) )\n",
    "            self.tree_list[i].is_built = True\n",
    "    \n",
    "    def set_node_id(self):\n",
    "        node_ids = [list() for i in range(self.tree_num)]\n",
    "        for i in range(self.tree_num):\n",
    "            self.tree_list[i].set_node_id(node_ids[i])\n",
    "\n",
    "    def set_random_id(self):\n",
    "        for i in range(self.tree_num):\n",
    "            self.tree_list[i].set_random_id(self.tree_dict)\n",
    "\n",
    "    # ノードの計算を保存するか決める関数\n",
    "    def set_save_flag(self):\n",
    "        # とりあえず，全部保存する方向でTrue\n",
    "        for i in range(self.tree_num):\n",
    "            # self.tree_list[i].set_save_flag(self.tree_dict)\n",
    "            self.tree_list[i].save_flag = True\n",
    "\n",
    "    def initialize_state(self):\n",
    "        for i in range(self.tree_num):\n",
    "            self.tree_list[i].is_built = False\n",
    "            self.tree_list[i].iteration = 0.0\n",
    "\n",
    "    def make_struct_dict(self):\n",
    "        struct_dict = {i : dict() for i in range(self.tree_num)}\n",
    "        for i in range(self.tree_num):\n",
    "            self.tree_list[i].make_struct_dict(struct_dict[i])\n",
    "        return struct_dict\n",
    "\n",
    "    def make_variable_dict(self, slot_index: int):\n",
    "        variable_dict = dict()\n",
    "        for i in range(self.tree_num):\n",
    "            variable_dict[i] = self.tree_list[i].slots[slot_index]\n",
    "        return variable_dict\n",
    "    \n",
    "    def update_step(self, gradient, parameter, slot_index):\n",
    "        # 複数の木で構成し，引数に他の木の出力を用いるときのために，\n",
    "        # 作成するvariable_dictの要素に各木の出力を保持するように変更\n",
    "        variable_dict = self.make_variable_dict(slot_index)\n",
    "        variable_dict[\"gradient\"] = gradient\n",
    "        variable_dict[\"parameter\"] = parameter\n",
    "        self.iteration_slots[slot_index].assign_add(tf.ones(parameter.shape))\n",
    "        variable_dict[\"iteration\"] = self.iteration_slots[slot_index]\n",
    "\n",
    "        for i in range(self.tree_num):\n",
    "            if not self.tree_list[i].skip_flag:\n",
    "                self.tree_list[i](variable_dict, slot_index)\n",
    "            \n",
    "        parameter.assign_sub(self.tree_list[self.tree_num-1].slots[slot_index])\n",
    "    \n",
    "    def apply_gradients(self, grad_and_vars):\n",
    "        for i in range(self.tree_num):\n",
    "            if self.tree_list[i].is_built == False:\n",
    "                var_list = [GaV[1] for GaV in grad_and_vars]\n",
    "                self.build(var_list)\n",
    "        for i, (G, V) in enumerate(grad_and_vars):\n",
    "            self.update_step(G, V, i)\n",
    "            \n",
    "    def mutation(self):\n",
    "        # 突然変異を行う次元の選択\n",
    "        mutate_index = random.choice(range(self.tree_num))\n",
    "\n",
    "        p = random.random()\n",
    "        # 遺伝子の削除 --> 削除して参照先がなくなってしまったときのために0として扱う \n",
    "        if p < 0.3:\n",
    "            tmp = FuncNode(max_depth = 1, function = SignFunc())\n",
    "            tmp.args[0] = ConstNode(depth = 1, constant = 0.0)\n",
    "            tmp.skip_flag = True\n",
    "            self.tree_list[mutate_index] = tmp\n",
    "        # 遺伝子の追加\n",
    "        elif p < 0.6:\n",
    "            tmp = FuncNode(max_depth = 1)\n",
    "            tmp.skip_flag = False\n",
    "            self.tree_list.insert(mutate_index, tmp)\n",
    "        # 要素の変更\n",
    "        else:\n",
    "            p = random.random()\n",
    "            # 葉の要素の変更\n",
    "            if p < 0.3:\n",
    "                for i in range(len(self.tree_list[mutate_index].args)):\n",
    "                    if random.choice([0, 1]):\n",
    "                        self.tree_list[mutate_index].args[i] = VarNode(depth = 1)\n",
    "                    else:\n",
    "                        self.tree_list[mutate_index].args[i] = ConstNode(depth = 1)\n",
    "            # 関数のみ変更\n",
    "            elif p < 0.6:\n",
    "                args = copy.deepcopy(self.tree_list[mutate_index].args)\n",
    "                self.tree_list[mutate_index] = FuncNode(max_depth = 1)\n",
    "                self.tree_list[mutate_index].skip_flag = False\n",
    "                if len(args) >= len(self.tree_list[mutate_index].args):\n",
    "                    for i in range(len(self.tree_list[mutate_index].args)):\n",
    "                        self.tree_list[mutate_index].args[i] = args[i]\n",
    "                else:\n",
    "                    self.tree_list[mutate_index].args[0] = args[0]\n",
    "                    if random.choice([0, 1]):\n",
    "                        self.tree_list[mutate_index].args[1] = VarNode(depth = 1)\n",
    "                    else:\n",
    "                        self.tree_list[mutate_index].args[1] = ConstNode(depth = 1)\n",
    "            # 全て変更\n",
    "            else:\n",
    "                self.tree_list[mutate_index] = FuncNode(max_depth = 1)\n",
    "                self.tree_list[mutate_index].skip_flag = False\n",
    "                \n",
    "        \n",
    "        self.tree_num = len(self.tree_list)\n",
    "        self.tree_dict = {i : {\"node_type\" : \"function\"} for i in range(self.tree_num)}\n",
    "\n",
    "        for i in range(self.tree_num):\n",
    "            for j in range(len(self.tree_list[i].args)):\n",
    "                if isinstance(self.tree_list[i].args[j], VarNode) and self.tree_list[i].args[j].variable_id == None:\n",
    "                    self.tree_list[i].set_random_id(self.tree_dict)\n",
    "        \n",
    "        self.set_node_id()\n",
    "        self.initialize_state()\n",
    "\n",
    "\n",
    "\n",
    "class SGD(TreeOptimizer):\n",
    "    def __init__(self, learning_rate:float = 0.001):\n",
    "\n",
    "        self.tree_num = 1\n",
    "        self.tree_list = [FuncNode(max_depth=self.max_depth) for i in range(self.tree_num)]\n",
    "        self.tree_dict = {i : {\"node_type\" : \"function\"} for i in range(self.tree_num)}\n",
    "\n",
    "        self.tree_list[0] = FuncNode(max_depth=self.max_depth, function=MulFunc())\n",
    "        self.tree_list[0].args[0] = ConstNode(depth = 2, constant = learning_rate)\n",
    "        self.tree_list[0].args[1] = VarNode(depth = 2, variable_id = \"gradient\")\n",
    "\n",
    "        self.set_node_id()\n",
    "        self.set_save_flag()\n",
    "        self.initialize_state()\n",
    "\n",
    "class Momentum(TreeOptimizer):\n",
    "    def __init__(self, learning_rate:float = 0.001, momentum=0.9):\n",
    "\n",
    "        self.tree_num = 3\n",
    "        self.tree_list = [FuncNode(max_depth=self.max_depth) for i in range(self.tree_num)]\n",
    "        self.tree_dict = {i : {\"node_type\" : \"function\"} for i in range(self.tree_num)}\n",
    "        # tree_list[0].slots = m * v_t\n",
    "        self.tree_list[0] = FuncNode(max_depth=self.max_depth, function=MulFunc())\n",
    "        self.tree_list[0].args[0] = ConstNode(depth = 1, constant = momentum)\n",
    "        self.tree_list[0].args[1] = VarNode(depth = 1, variable_id = 2)\n",
    "        # tree_list[1].slots = lr * gradient\n",
    "        self.tree_list[1] = FuncNode(max_depth=self.max_depth, function=MulFunc())\n",
    "        self.tree_list[1].args[0] = ConstNode(depth = 1, constant = learning_rate)\n",
    "        self.tree_list[1].args[1] = VarNode(depth = 1, variable_id=\"gradient\")\n",
    "        # tree_list[2].slots = tree_list[0].slots - tree_list[1].slots\n",
    "        self.tree_list[2] = FuncNode(max_depth=self.max_depth, function=AddFunc())\n",
    "        self.tree_list[2].args[0] = VarNode(depth = 1, variable_id = 0)\n",
    "        self.tree_list[2].args[1] = VarNode(depth = 1, variable_id = 1)\n",
    "    \n",
    "        self.set_node_id()\n",
    "        self.set_save_flag()\n",
    "        self.initialize_state()\n",
    "\n",
    "class RMSProp(TreeOptimizer):\n",
    "    def __init__(self, learning_rate = 0.001, rho = 0.9, epsilon = 1e-7):\n",
    "        self.tree_num = 9\n",
    "        self.tree_list = [FuncNode(max_depth=self.max_depth) for i in range(self.tree_num)]\n",
    "        self.tree_dict = {i : {\"node_type\" : \"function\"} for i in range(self.tree_num)}\n",
    "\n",
    "        # rho * h_t\n",
    "        self.tree_list[0] = FuncNode(max_depth = 1, function=MulFunc())\n",
    "        self.tree_list[0].args[0] = ConstNode(depth = 1, constant = rho)\n",
    "        self.tree_list[0].args[1] = VarNode(depth = 1, variable_id = 4)\n",
    "        # 1.0 - rho\n",
    "        self.tree_list[1] = FuncNode(max_depth = 1, function=SubFunc())\n",
    "        self.tree_list[1].args[0] = ConstNode(depth = 1, constant = 1.0)\n",
    "        self.tree_list[1].args[1] = ConstNode(depth = 1, constant = rho)\n",
    "        # gradient ^ 2\n",
    "        self.tree_list[2] = FuncNode(max_depth = 1, function=SquareFunc())\n",
    "        self.tree_list[2].args[0] = VarNode(depth = 1, variable_id = \"gradient\")\n",
    "        # (1.0 - rho) * gradient ^ 2\n",
    "        self.tree_list[3] = FuncNode(max_depth = 1, function=MulFunc())\n",
    "        self.tree_list[3].args[0] = VarNode(depth = 1, variable_id = 1)\n",
    "        self.tree_list[3].args[1] = VarNode(depth = 1, variable_id = 2)\n",
    "        # rho * h_t + (1.0 - rho) * gradient ^ 2\n",
    "        self.tree_list[4] = FuncNode(max_depth = 1, function=AddFunc())\n",
    "        self.tree_list[4].args[0] = VarNode(depth = 1, variable_id = 0)\n",
    "        self.tree_list[4].args[1] = VarNode(depth = 1, variable_id = 3)\n",
    "        # sqrt(h_t+1)\n",
    "        self.tree_list[5] = FuncNode(max_depth = 1, function = SqrtFunc())\n",
    "        self.tree_list[5].args[0] = VarNode(depth = 1, variable_id = 4)\n",
    "        # h_t+1 + epsilon\n",
    "        self.tree_list[6] = FuncNode(max_depth = 1, function=AddFunc())\n",
    "        self.tree_list[6].args[0] = ConstNode(depth = 1, constant = epsilon)\n",
    "        self.tree_list[6].args[1] = VarNode(depth = 1, variable_id = 5)\n",
    "        # learning_rate / sqrt(h_t+1 + epsilon)\n",
    "        self.tree_list[7] = FuncNode(max_depth = 1, function = DivFunc())\n",
    "        self.tree_list[7].args[0] = ConstNode(depth = 1, constant = learning_rate)\n",
    "        self.tree_list[7].args[1] = VarNode(depth = 1, variable_id = 6)\n",
    "        # {learning_rate / sqrt(h_t+1 + epsilon)} * gradient\n",
    "        self.tree_list[8] = FuncNode(max_depth = 1, function = MulFunc())\n",
    "        self.tree_list[8].args[0] = VarNode(depth = 1, variable_id = 7)\n",
    "        self.tree_list[8].args[1] = VarNode(depth = 1, variable_id = \"gradient\")\n",
    "\n",
    "        self.set_node_id()\n",
    "        self.set_save_flag()\n",
    "        self.initialize_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 10\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "    x_train, x_test = x_train[..., tf.newaxis] / 255.0, x_test[..., tf.newaxis] / 255.0\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(BATCH_SIZE)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def build_model():\n",
    "    input = layers.Input(shape = (32, 32, 3))\n",
    "    x = layers.Conv2D(32, 3, 2)(input)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(units = 32, activation = \"relu\")(x)\n",
    "    output = layers.Dense(units = 10, activation = \"softmax\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "train_dataset, test_dataset = load_data()\n",
    "\n",
    "model = build_model()\n",
    "model.save_weights(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.RMSprop(learning_rate=0.001,)\n",
    "\n",
    "model.load_weights(\"model.keras\")\n",
    "\n",
    "loss_obj = metrics.Mean()\n",
    "accuracy_obj = metrics.SparseCategoricalAccuracy()\n",
    "val_loss_obj = metrics.SparseCategoricalCrossentropy()\n",
    "val_accuracy_obj = metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(X, Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(X)\n",
    "        loss = losses.SparseCategoricalCrossentropy()(Y, pred)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    loss_obj(loss)\n",
    "    accuracy_obj(Y, pred)\n",
    "\n",
    "@tf.function\n",
    "def test_step(X, Y):\n",
    "    pred = model(X)\n",
    "    \n",
    "    val_loss_obj(Y, pred)\n",
    "    val_accuracy_obj(Y, pred)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    \n",
    "    loss_obj.reset_state()\n",
    "    accuracy_obj.reset_state()\n",
    "    val_loss_obj.reset_state()\n",
    "    val_accuracy_obj.reset_state()\n",
    "\n",
    "    for X, Y in tqdm(train_dataset):\n",
    "        train_step(X, Y)\n",
    "        \n",
    "    for X, Y in tqdm(test_dataset):\n",
    "        test_step(X, Y)\n",
    "\n",
    "    print(f\"epoch : {i}, loss : {float(loss_obj.result())}, accuracy : {float(accuracy_obj.result())}\")\n",
    "    print(f\"val_loss : {float(val_loss_obj.result())}, val_accuracy : {float(val_accuracy_obj.result())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSProp()\n",
    "\n",
    "model.load_weights(\"model.keras\")\n",
    "\n",
    "loss_obj = metrics.Mean()\n",
    "accuracy_obj = metrics.SparseCategoricalAccuracy()\n",
    "val_loss_obj = metrics.SparseCategoricalCrossentropy()\n",
    "val_accuracy_obj = metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(X, Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(X)\n",
    "        loss = losses.SparseCategoricalCrossentropy()(Y, pred)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    loss_obj(loss)\n",
    "    accuracy_obj(Y, pred)\n",
    "\n",
    "@tf.function\n",
    "def test_step(X, Y):\n",
    "    pred = model(X)\n",
    "    \n",
    "    val_loss_obj(Y, pred)\n",
    "    val_accuracy_obj(Y, pred)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    \n",
    "    loss_obj.reset_state()\n",
    "    accuracy_obj.reset_state()\n",
    "    val_loss_obj.reset_state()\n",
    "    val_accuracy_obj.reset_state()\n",
    "\n",
    "    for X, Y in tqdm(train_dataset):\n",
    "        train_step(X, Y)\n",
    "        \n",
    "    for X, Y in tqdm(test_dataset):\n",
    "        test_step(X, Y)\n",
    "\n",
    "    print(f\"epoch : {i}, loss : {float(loss_obj.result())}, accuracy : {float(accuracy_obj.result())}\")\n",
    "    print(f\"val_loss : {float(val_loss_obj.result())}, val_accuracy : {float(val_accuracy_obj.result())}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
